{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#!7z.exe e dota2.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] Системе не удается найти указанный путь: 'dota2\\\\dota2'\n",
      "C:\\Grisha\\МФТИ\\МашинноеОсновыЮдин\\HW2\\env\\dota2\\dota2\n"
     ]
    }
   ],
   "source": [
    "%cd dota2\\dota2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip 19.00 (x64) : Copyright (c) 1999-2018 Igor Pavlov : 2019-02-21\n",
      "\n",
      "Scanning the drive for archives:\n",
      "1 file, 11608616 bytes (12 MiB)\n",
      "\n",
      "Extracting archive: features.csv.zip\n",
      "--\n",
      "Path = features.csv.zip\n",
      "Type = zip\n",
      "Physical Size = 11608616\n",
      "\n",
      "Everything is Ok\n",
      "\n",
      "Size:       33074264\n",
      "Compressed: 11608616\n"
     ]
    }
   ],
   "source": [
    "#!7z.exe e features.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>lobby_type</th>\n",
       "      <th>r1_hero</th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>dire_boots_count</th>\n",
       "      <th>dire_ward_observer_count</th>\n",
       "      <th>dire_ward_sentry_count</th>\n",
       "      <th>dire_first_ward_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>radiant_win</th>\n",
       "      <th>tower_status_radiant</th>\n",
       "      <th>tower_status_dire</th>\n",
       "      <th>barracks_status_radiant</th>\n",
       "      <th>barracks_status_dire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1430198770</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2098</td>\n",
       "      <td>1489</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>2874</td>\n",
       "      <td>1</td>\n",
       "      <td>1796</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1430220345</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1188</td>\n",
       "      <td>1033</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2463</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1430227081</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1319</td>\n",
       "      <td>1270</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id  start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
       "0         0  1430198770           7       11         5   2098     1489     20   \n",
       "1         1  1430220345           0       42         4   1188     1033      9   \n",
       "2         2  1430227081           7       33         4   1319     1270     22   \n",
       "\n",
       "   r1_kills  r1_deaths  ...  dire_boots_count  dire_ward_observer_count  \\\n",
       "0         0          0  ...                 4                         2   \n",
       "1         0          1  ...                 4                         3   \n",
       "2         0          0  ...                 4                         3   \n",
       "\n",
       "   dire_ward_sentry_count  dire_first_ward_time  duration  radiant_win  \\\n",
       "0                       2                 -52.0      2874            1   \n",
       "1                       1                  -5.0      2463            1   \n",
       "2                       1                  13.0      2130            0   \n",
       "\n",
       "   tower_status_radiant  tower_status_dire  barracks_status_radiant  \\\n",
       "0                  1796                  0                       51   \n",
       "1                  1974                  0                       63   \n",
       "2                     0               1830                        0   \n",
       "\n",
       "   barracks_status_dire  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                    63  \n",
       "\n",
       "[3 rows x 109 columns]"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'start_time', 'lobby_type', 'r1_hero', 'r1_level', 'r1_xp',\n",
       "       'r1_gold', 'r1_lh', 'r1_kills', 'r1_deaths'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193087"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверяем наличие nan в данных\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_nan - имена колонок с пропущенными значениями\n",
    "col_ind_nan = np.arange(data.columns.shape[0])[data.isnull().sum() > 0]\n",
    "col_nan = data.columns[col_ind_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97230 entries, 0 to 97229\n",
      "Data columns (total 12 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   first_blood_time             77677 non-null  float64\n",
      " 1   first_blood_team             77677 non-null  float64\n",
      " 2   first_blood_player1          77677 non-null  float64\n",
      " 3   first_blood_player2          53243 non-null  float64\n",
      " 4   radiant_bottle_time          81539 non-null  float64\n",
      " 5   radiant_courier_time         96538 non-null  float64\n",
      " 6   radiant_flying_courier_time  69751 non-null  float64\n",
      " 7   radiant_first_ward_time      95394 non-null  float64\n",
      " 8   dire_bottle_time             81087 non-null  float64\n",
      " 9   dire_courier_time            96554 non-null  float64\n",
      " 10  dire_flying_courier_time     71132 non-null  float64\n",
      " 11  dire_first_ward_time         95404 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 8.9 MB\n"
     ]
    }
   ],
   "source": [
    "data[col_nan].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Признак - время возникновения события, если событие не возникает то время его появления -1.\n",
    "event_time_features = [\"first_blood_time\", \"radiant_bottle_time\", \"radiant_courier_time\", \n",
    "                       \"radiant_flying_courier_time\", \"radiant_first_ward_time\", \"dire_bottle_time\", \n",
    "                      \"dire_courier_time\", \"dire_flying_courier_time\", \"dire_first_ward_time\"]\n",
    "\n",
    "for feat in event_time_features:\n",
    "    data[feat] = data[feat].fillna(-1)\n",
    "\n",
    "    \n",
    "#Признаки first blood player. значение признака NAN в том случае, если первая кровь не произошла.\n",
    "#по этому оба признака будут равны номеру не существующего игрока 0.\n",
    "data[\"first_blood_player1\"] = data[\"first_blood_player1\"].fillna(0)\n",
    "data[\"first_blood_player2\"] = data[\"first_blood_player2\"].fillna(0)\n",
    "\n",
    "#Признак first_blood_team равен -1 если ни одна из команд не совершила первую кровь\n",
    "data[\"first_blood_team\"] = data[\"first_blood_team\"].fillna(-1)\n",
    "\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделяем целевую переменную, а так же признаки\n",
    "target = ['radiant_win']\n",
    "features = list(filter(lambda x: x != target[0], data.columns))\n",
    "\n",
    "#Пока не будем учитывать те признаки, которых нет в тестовых данных в целях формирования baseline\n",
    "#Так как опытным путем проверенно, что эти признаки почти однозначно определяют команду победителя,\n",
    "#то обучая модель на этих признаках, нам придется их искуственно генерировать для тестовых данных\n",
    "#тем самым мы искуственно сгенерируем таргет признак для тестовых данных.\n",
    "added_features = [\"duration\",\n",
    "                 \"tower_status_radiant\",\n",
    "                 \"tower_status_dire\",\n",
    "                 \"barracks_status_radiant\",\n",
    "                 \"barracks_status_dire\"]\n",
    "\n",
    "for feat in added_features: features.remove(feat)\n",
    "#так же удалим признаки, которые не несут информации для предсказания\n",
    "features.remove(\"match_id\")\n",
    "features.remove(\"start_time\")\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Так как соревнования уже не существует, будем использовать в качестве тестовой выборки 20% от текущей\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data[features].to_numpy()\n",
    "y = data[target].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\grisha\\staj\\conda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\grisha\\staj\\conda\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\grisha\\staj\\conda\\lib\\site-packages (from xgboost) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "model = XGBClassifier(eval_metric='mlogloss',  \n",
    "                      use_label_encoder=False, \n",
    "                      n_jobs=-1)\n",
    "\n",
    "#result = cross_val_score(model, X, y, scoring=auc_scorer, cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test roc-auc: 0.6420604185004228\n"
     ]
    }
   ],
   "source": [
    "#Проверка метрики\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"test roc-auc:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Grisha\\Staj\\conda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='mlogloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None...\n",
       "       413.63636364, 418.18181818, 422.72727273, 427.27272727,\n",
       "       431.81818182, 436.36363636, 440.90909091, 445.45454545,\n",
       "       450.        , 454.54545455, 459.09090909, 463.63636364,\n",
       "       468.18181818, 472.72727273, 477.27272727, 481.81818182,\n",
       "       486.36363636, 490.90909091, 495.45454545, 500.        ])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=make_scorer(roc_auc_score), verbose=0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#будем перебирать гиперпараметры для XGB \n",
    "n_estimators = np.linspace(50, 500, 100)\n",
    "eta = [0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "\n",
    "param_grid = [\n",
    "    {'eta' : eta},\n",
    "    {'n_estimators' : n_estimators}\n",
    "  ]\n",
    "xgb_model = XGBClassifier(random_state = 0, eval_metric='mlogloss', \n",
    "                          use_label_encoder=False,\n",
    "                          n_jobs=-1)\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5,\n",
    "                           scoring=auc_scorer,\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.6489185887896615\n",
      "eta: 0.1 \t n_estimators: 100\n",
      "test roc-auc: 0.6441757969033239\n"
     ]
    }
   ],
   "source": [
    "print(\"train score:\", grid_search.best_score_)\n",
    "print(\"eta:\", grid_search.best_estimator_.get_params()[\"eta\"], \"\\t\", \"n_estimators:\",\n",
    "    grid_search.best_estimator_.get_params()[\"n_estimators\"])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"test roc-auc:\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Предобработаем признаки перед тем как использовать нейронную сеть\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_to_transform_cols = ['lobby_type', 'r1_hero', 'first_blood_player1', 'first_blood_player2',\n",
    "                         'first_blood_team' \n",
    "                        ]\n",
    "num_features = [feat for feat in features if feat not in cat_to_transform_cols]\n",
    "\n",
    "#кодирование категориальных признаков\n",
    "cat_data = pd.get_dummies(data[cat_to_transform_cols].applymap(lambda x: str(x)), drop_first=True)\n",
    "data = pd.concat([data[num_features], cat_data], axis=1)\n",
    "\n",
    "#разбиение на тест и трейн\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "#нормализация численных признаков\n",
    "for feat in num_features:\n",
    "    scaler = StandardScaler()\n",
    "    train_data[feat] = scaler.fit_transform(train_data[feat][:, np.newaxis]) \n",
    "    test_data[feat] = scaler.transform(test_data[feat][:, np.newaxis]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r1_level</th>\n",
       "      <th>r1_xp</th>\n",
       "      <th>r1_gold</th>\n",
       "      <th>r1_lh</th>\n",
       "      <th>r1_kills</th>\n",
       "      <th>r1_deaths</th>\n",
       "      <th>r1_items</th>\n",
       "      <th>r2_hero</th>\n",
       "      <th>r2_level</th>\n",
       "      <th>r2_xp</th>\n",
       "      <th>...</th>\n",
       "      <th>first_blood_player2_2.0</th>\n",
       "      <th>first_blood_player2_3.0</th>\n",
       "      <th>first_blood_player2_4.0</th>\n",
       "      <th>first_blood_player2_5.0</th>\n",
       "      <th>first_blood_player2_6.0</th>\n",
       "      <th>first_blood_player2_7.0</th>\n",
       "      <th>first_blood_player2_8.0</th>\n",
       "      <th>first_blood_player2_9.0</th>\n",
       "      <th>first_blood_team_0.0</th>\n",
       "      <th>first_blood_team_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11153</th>\n",
       "      <td>-1.294497</td>\n",
       "      <td>-1.307383</td>\n",
       "      <td>-0.747402</td>\n",
       "      <td>-1.242827</td>\n",
       "      <td>-0.538007</td>\n",
       "      <td>-0.577933</td>\n",
       "      <td>0.692287</td>\n",
       "      <td>0.267122</td>\n",
       "      <td>-1.240466</td>\n",
       "      <td>-0.882647</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>1.400398</td>\n",
       "      <td>1.399843</td>\n",
       "      <td>0.808301</td>\n",
       "      <td>0.638986</td>\n",
       "      <td>0.970857</td>\n",
       "      <td>-0.577933</td>\n",
       "      <td>0.292138</td>\n",
       "      <td>-0.772275</td>\n",
       "      <td>-0.328650</td>\n",
       "      <td>-0.325279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71813</th>\n",
       "      <td>-0.396199</td>\n",
       "      <td>-0.818529</td>\n",
       "      <td>-0.969645</td>\n",
       "      <td>-0.800047</td>\n",
       "      <td>-0.538007</td>\n",
       "      <td>-0.577933</td>\n",
       "      <td>0.292138</td>\n",
       "      <td>1.000813</td>\n",
       "      <td>0.583167</td>\n",
       "      <td>0.529713</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r1_level     r1_xp   r1_gold     r1_lh  r1_kills  r1_deaths  r1_items  \\\n",
       "11153 -1.294497 -1.307383 -0.747402 -1.242827 -0.538007  -0.577933  0.692287   \n",
       "20559  1.400398  1.399843  0.808301  0.638986  0.970857  -0.577933  0.292138   \n",
       "71813 -0.396199 -0.818529 -0.969645 -0.800047 -0.538007  -0.577933  0.292138   \n",
       "\n",
       "        r2_hero  r2_level     r2_xp  ...  first_blood_player2_2.0  \\\n",
       "11153  0.267122 -1.240466 -0.882647  ...                        0   \n",
       "20559 -0.772275 -0.328650 -0.325279  ...                        0   \n",
       "71813  1.000813  0.583167  0.529713  ...                        1   \n",
       "\n",
       "       first_blood_player2_3.0  first_blood_player2_4.0  \\\n",
       "11153                        0                        0   \n",
       "20559                        0                        0   \n",
       "71813                        0                        0   \n",
       "\n",
       "       first_blood_player2_5.0  first_blood_player2_6.0  \\\n",
       "11153                        0                        0   \n",
       "20559                        0                        0   \n",
       "71813                        0                        0   \n",
       "\n",
       "       first_blood_player2_7.0  first_blood_player2_8.0  \\\n",
       "11153                        0                        0   \n",
       "20559                        0                        0   \n",
       "71813                        0                        0   \n",
       "\n",
       "       first_blood_player2_9.0  first_blood_team_0.0  first_blood_team_1.0  \n",
       "11153                        0                     1                     0  \n",
       "20559                        0                     1                     0  \n",
       "71813                        0                     0                     1  \n",
       "\n",
       "[3 rows x 225 columns]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.10.1-cp38-cp38-win_amd64.whl (226.6 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\grisha\\staj\\conda\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим обьекты dataset и dataloader для загрузки наших данных\n",
    "class dataset_(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.X[idx, :]\n",
    "        sample_y = self.y[idx]\n",
    "        out_y = torch.zeros(len(np.unique(self.y)), dtype=torch.float)\n",
    "        out_y[sample_y.item()] = 1\n",
    "        #return {\"sample\" : torch.tensor(sample_x, dtype=torch.float), \n",
    "        #        \"target\" : torch.tensor(sample_y, dtype=torch.float)}   \n",
    "        return {\"sample\" : torch.tensor(sample_x, dtype=torch.float), \n",
    "                \"target\" : out_y}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.to_numpy()\n",
    "X_test = test_data.to_numpy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "train_dataset = dataset_(X_train, y_train)\n",
    "val_dataset = dataset_(X_val, y_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализируем модель\n",
    "class neural_model(nn.Module):\n",
    "    def __init__(self, input_n):\n",
    "        super(neural_model, self).__init__()\n",
    "        self.f1 = nn.Linear(input_n, 256)\n",
    "        self.f2 = nn.Linear(256, 412)\n",
    "        self.f3 = nn.Linear(412, 256)\n",
    "        self.f4 = nn.Linear(256, 2)\n",
    "        self.out = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.f1(x))\n",
    "        x = F.relu(self.f2(x))\n",
    "        x = F.relu(self.f3(x))\n",
    "        x = self.f4(x)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "model = neural_model(X_train.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1a0c3715c54a85a3b791b556adf29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.6905851364135742 acc: 0.5223061041292639 prec: 0.521263138593472 rec: 0.998914334007633 roc: 0.5023595788720455\n",
      "val loss: 0.6814878918230534 acc: 0.597794434470377 prec: 0.5709117806048699 rec: 0.9108538584137849 roc: 0.5851222916045254\n",
      "val loss: 0.6465945355594158 acc: 0.6423850987432675 prec: 0.6479293302185021 rec: 0.6838242929673555 roc: 0.6404123781899738\n",
      "val loss: 0.630992703139782 acc: 0.6475455565529623 prec: 0.6628284248409184 rec: 0.6581304749107877 roc: 0.6470933941080801\n",
      "val loss: 0.6263057477772236 acc: 0.652241472172352 prec: 0.6623001220102082 rec: 0.6776260504343438 roc: 0.6511699251966507\n",
      "val loss: 0.6252595894038677 acc: 0.6550100987432674 prec: 0.6653227633887088 rec: 0.6771880239841337 roc: 0.6541148269530535\n",
      "val loss: 0.6241387240588665 acc: 0.6575667639138241 prec: 0.6695158624606421 rec: 0.6764904200891905 roc: 0.6567726574751576\n",
      "val loss: 0.6244946867227554 acc: 0.6555327648114901 prec: 0.6716231277301686 rec: 0.6625341637512439 roc: 0.6553089694218837\n",
      "val loss: 0.6239574737846851 acc: 0.6563821813285459 prec: 0.6669484269419078 rec: 0.6765299883521423 roc: 0.6552726432859171\n",
      "val loss: 0.6233067810535431 acc: 0.6571106373429084 prec: 0.6648905528524787 rec: 0.6885122046899533 roc: 0.6556013553256069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Опишем тренеровочный цикл\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "epoches = 20\n",
    "for epoch in tqdm(range(epoches)):\n",
    "    for train_batch in train_loader:\n",
    "        x_train_batch = train_batch[\"sample\"]\n",
    "        y_train_batch = train_batch[\"target\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train_batch)\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        mean_loss = []\n",
    "        mean_val_acc = []\n",
    "        mean_val_prec = []\n",
    "        mean_val_recall = []\n",
    "        mean_val_roc_auc = []\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                x_val_batch = val_batch[\"sample\"]\n",
    "                y_val_batch = val_batch[\"target\"]\n",
    "\n",
    "                y_pred = model(x_val_batch)\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val_batch)\n",
    "                \n",
    "                y_pred = [pred.argmax().item() for pred in y_pred]\n",
    "                y_val_batch = [true.argmax().item() for true in y_val_batch]    \n",
    "                mean_loss.append(loss.numpy())\n",
    "                mean_val_acc.append(accuracy_score(y_val_batch, y_pred))\n",
    "                mean_val_prec.append(precision_score(y_val_batch, y_pred))\n",
    "                mean_val_recall.append(recall_score(y_val_batch, y_pred))\n",
    "                mean_val_roc_auc.append(roc_auc_score(y_val_batch, y_pred))\n",
    "\n",
    "            print(\"val loss:\", sum(mean_loss) / len(mean_loss), \n",
    "                  \"acc:\", sum(mean_val_acc) / len(mean_val_acc), \n",
    "                  \"prec:\", sum(mean_val_prec) / len(mean_val_prec), \n",
    "                  \"rec:\", sum(mean_val_recall) / len(mean_val_recall), \n",
    "                  \"roc:\", sum(mean_val_roc_auc) / len(mean_val_roc_auc)\n",
    "             )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset_(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.6501594158181632 prec: 0.6641520525129813 rec: 0.6676186724443569 roc: 0.64934958589932\n"
     ]
    }
   ],
   "source": [
    "#Проверка качества на тесте\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(test_loader))\n",
    "    x_test_batch = test_batch[\"sample\"]\n",
    "    y_test_batch = test_batch[\"target\"]\n",
    "\n",
    "    y_pred = model(x_test_batch)\n",
    "    y_pred = [pred.argmax().item() for pred in y_pred]\n",
    "    y_test_batch = [true.argmax().item() for true in y_test_batch] \n",
    "\n",
    "    print(\"test\", \"acc:\", accuracy_score(y_test_batch, y_pred), \n",
    "          \"prec:\", precision_score(y_test_batch, y_pred), \n",
    "          \"rec:\", recall_score(y_test_batch, y_pred), \n",
    "          \"roc:\", roc_auc_score(y_test_batch, y_pred)\n",
    "     )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем данные для создания временного ряда\n",
    "data = pd.read_csv('features.csv')\n",
    "\n",
    "col_ind_nan = np.arange(data.columns.shape[0])[data.isnull().sum() > 0]\n",
    "col_nan = data.columns[col_ind_nan]\n",
    "\n",
    "\n",
    "event_time_features = [\"first_blood_time\", \"radiant_bottle_time\", \"radiant_courier_time\", \n",
    "                       \"radiant_flying_courier_time\", \"radiant_first_ward_time\", \"dire_bottle_time\", \n",
    "                      \"dire_courier_time\", \"dire_flying_courier_time\", \"dire_first_ward_time\"]\n",
    "\n",
    "for feat in event_time_features:\n",
    "    data[feat] = data[feat].fillna(-1)\n",
    "\n",
    "data[\"first_blood_player1\"] = data[\"first_blood_player1\"].fillna(0)\n",
    "data[\"first_blood_player2\"] = data[\"first_blood_player2\"].fillna(0)\n",
    "\n",
    "data[\"first_blood_team\"] = data[\"first_blood_team\"].fillna(-1)\n",
    "\n",
    "target = ['radiant_win']\n",
    "features = list(filter(lambda x: x != target[0], data.columns))\n",
    "\n",
    "added_features = [\"duration\",\n",
    "                 \"tower_status_radiant\",\n",
    "                 \"tower_status_dire\",\n",
    "                 \"barracks_status_radiant\",\n",
    "                 \"barracks_status_dire\"]\n",
    "\n",
    "for feat in added_features: features.remove(feat)\n",
    "    \n",
    "features.remove(\"match_id\")\n",
    "features.remove(\"start_time\")\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Каждый обьект будет представлять собою 4 вектора x0, x1, x2, x3, x4\n",
    "#xi содержит инфомацию о событиях произошедших между i и i + 1 минутами\n",
    "min_time = -300 #начало игры\n",
    "max_time = 300 #конец игры\n",
    "\n",
    "diff = abs(max_time - min_time) // 4\n",
    "time_range = [min_time + i * diff for i in range(5)]\n",
    "X = np.array([[[1 if (time_range[j] < data[col][i] <= time_range[j + 1]) else 0 for col in event_time_features] for j in range(4)] for i in range(data.shape[0])])\n",
    "y = data[target].to_numpy()\n",
    "\n",
    "X.shape #количеств обьектов x 4 x длина вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_events_cols = [col for col in features if col not in event_time_features]\n",
    "\n",
    "\n",
    "\n",
    "cat_to_transform_cols = ['lobby_type', 'r1_hero', 'first_blood_player1', 'first_blood_player2',\n",
    "                         'first_blood_team' \n",
    "                        ]\n",
    "num_features = [feat for feat in not_events_cols if feat not in cat_to_transform_cols]\n",
    "\n",
    "#кодирование категориальных признаков\n",
    "cat_data = pd.get_dummies(data[cat_to_transform_cols].applymap(lambda x: str(x)), drop_first=True)\n",
    "adding_data = pd.concat([data[num_features], cat_data], axis=1)\n",
    "\n",
    "#разбиение на тест и трейн\n",
    "train_adding, test_adding = train_test_split(adding_data, test_size=0.2, random_state=0)\n",
    "\n",
    "#нормализация численных признаков\n",
    "for feat in num_features:\n",
    "    scaler = StandardScaler()\n",
    "    train_adding[feat] = scaler.fit_transform(train_data[feat][:, np.newaxis]) \n",
    "    test_adding[feat] = scaler.transform(test_data[feat][:, np.newaxis]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создадим обьекты dataset и dataloader для загрузки наших данных\n",
    "class time_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, adding_data):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.adding_data = adding_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_x = self.X[idx, :, :]\n",
    "        sample_add = self.adding_data[idx, :]\n",
    "        sample_y = self.y[idx]\n",
    "        out_y = torch.zeros(len(np.unique(self.y)), dtype=torch.float)\n",
    "        out_y[sample_y.item()] = 1  \n",
    "        return {\"sample\" : torch.tensor(sample_x, dtype=torch.float),\n",
    "                \"adding\" : torch.tensor(sample_add, dtype=torch.float),\n",
    "                \"target\" : out_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиение на тренеровочну, валидационную, тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "train_adding, val_adding = train_test_split(train_adding, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "train_adding = train_adding.to_numpy()\n",
    "val_adding = val_adding.to_numpy()\n",
    "test_adding = test_adding.to_numpy()\n",
    "\n",
    "\n",
    "train_dataset = time_dataset(X_train, y_train, train_adding)\n",
    "val_dataset = time_dataset(X_val, y_val, val_adding)\n",
    "test_dataset = time_dataset(X_test, y_test, test_adding)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Изменим модель реккуретной нейронной сети.\n",
    "#Так как мы имеем данные, которые не привязаны ко времени (после 1й минуты после 2й и тд.)\n",
    "#но которые являются результатом после 5ти минут игры(количество смертей героя), то\n",
    "#будем эти данные подавать после скрытых слоев на вход нейронной сети, чтобы они тоже\n",
    "#вносили свой вклад в предсказание\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=128, num_layers=2, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=728, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=2)\n",
    "        self.out = nn.Softmax(dim=-1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, adding):\n",
    "        x = torch.tanh(self.lstm1(x)[0])\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        #добавляем данные после пяти минут игры\n",
    "        x = torch.concat([x, adding], axis=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return self.out(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[2]\n",
    "model = RNN(input_size)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(iter(train_loader))\n",
    "x_train_batch = train_batch[\"sample\"]\n",
    "adding_batch = train_batch[\"adding\"]\n",
    "y_train_batch = train_batch[\"target\"]\n",
    "\n",
    "y_pred = model(x_train_batch, adding_batch)\n",
    "loss = nn.CrossEntropyLoss()(y_pred, y_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97802b17c7a48378e3bc4a1182cc870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.6879000812768936 acc: 0.5559238105924597 prec: 0.5410128062142929 rec: 0.9650511237897996 roc: 0.5388138099399032\n",
      "val loss: 0.663640946149826 acc: 0.6342374326750448 prec: 0.6268816567615105 rec: 0.7361092217813624 roc: 0.6298759405385359\n",
      "val loss: 0.6372556276619434 acc: 0.6450981822262118 prec: 0.6568846296036409 rec: 0.6684315746886387 roc: 0.6438658125921302\n",
      "val loss: 0.6295940577983856 acc: 0.6529205565529624 prec: 0.6631092973602071 rec: 0.6751374923514516 roc: 0.6519274902170477\n",
      "val loss: 0.6263429261744022 acc: 0.6533324730700178 prec: 0.6616667901606311 rec: 0.681781853553855 roc: 0.6520965663274095\n",
      "val loss: 0.6252095587551594 acc: 0.6528368491921006 prec: 0.661391161288172 rec: 0.6843636950464209 roc: 0.6516872990307945\n",
      "val loss: 0.6244991086423397 acc: 0.6546848070017954 prec: 0.6668060037885433 rec: 0.6728381071321846 roc: 0.6537923897571469\n",
      "val loss: 0.6238073222339153 acc: 0.6548280969479354 prec: 0.6647388701371408 rec: 0.679923601678941 roc: 0.6537126458853565\n",
      "val loss: 0.6235913373529911 acc: 0.6538054308797129 prec: 0.6632762320990306 rec: 0.6786810951724956 roc: 0.6527454322288454\n",
      "val loss: 0.6235972680151463 acc: 0.6536661804308797 prec: 0.6616658354219005 rec: 0.6854535969384106 roc: 0.6522568465758262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoches = 20\n",
    "for epoch in tqdm(range(epoches)):\n",
    "    for train_batch in train_loader:\n",
    "        x_train_batch = train_batch[\"sample\"]\n",
    "        train_adding_batch = train_batch[\"adding\"]\n",
    "        y_train_batch = train_batch[\"target\"]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train_batch, train_adding_batch)\n",
    "        loss = nn.CrossEntropyLoss()(y_pred, y_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 2 == 0:\n",
    "        mean_loss = []\n",
    "        mean_val_acc = []\n",
    "        mean_val_prec = []\n",
    "        mean_val_recall = []\n",
    "        mean_val_roc_auc = []\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                x_val_batch = val_batch[\"sample\"]\n",
    "                val_adding_batch = val_batch[\"adding\"]\n",
    "                y_val_batch = val_batch[\"target\"]\n",
    "\n",
    "                y_pred = model(x_val_batch, val_adding_batch)\n",
    "                loss = nn.CrossEntropyLoss()(y_pred, y_val_batch)\n",
    "                \n",
    "                y_pred = [pred.argmax().item() for pred in y_pred]\n",
    "                y_val_batch = [true.argmax().item() for true in y_val_batch]    \n",
    "                mean_loss.append(loss.numpy())\n",
    "                mean_val_acc.append(accuracy_score(y_val_batch, y_pred))\n",
    "                mean_val_prec.append(precision_score(y_val_batch, y_pred))\n",
    "                mean_val_recall.append(recall_score(y_val_batch, y_pred))\n",
    "                mean_val_roc_auc.append(roc_auc_score(y_val_batch, y_pred))\n",
    "\n",
    "            print(\"val loss:\", sum(mean_loss) / len(mean_loss), \n",
    "                  \"acc:\", sum(mean_val_acc) / len(mean_val_acc), \n",
    "                  \"prec:\", sum(mean_val_prec) / len(mean_val_prec), \n",
    "                  \"rec:\", sum(mean_val_recall) / len(mean_val_recall), \n",
    "                  \"roc:\", sum(mean_val_roc_auc) / len(mean_val_roc_auc)\n",
    "             )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.6524220919469299 prec: 0.6653677545056016 rec: 0.6726413236163088 roc: 0.6514842433837033\n"
     ]
    }
   ],
   "source": [
    "#Проверка качества на тесте\n",
    "with torch.no_grad():\n",
    "    test_batch = next(iter(test_loader))\n",
    "    x_test_batch = test_batch[\"sample\"]\n",
    "    test_adding_batch = test_batch[\"adding\"]\n",
    "    y_test_batch = test_batch[\"target\"]\n",
    "\n",
    "    y_pred = model(x_test_batch, test_adding_batch)\n",
    "    y_pred = [pred.argmax().item() for pred in y_pred]\n",
    "    y_test_batch = [true.argmax().item() for true in y_test_batch] \n",
    "\n",
    "    print(\"test\", \"acc:\", accuracy_score(y_test_batch, y_pred), \n",
    "          \"prec:\", precision_score(y_test_batch, y_pred), \n",
    "          \"rec:\", recall_score(y_test_batch, y_pred), \n",
    "          \"roc:\", roc_auc_score(y_test_batch, y_pred)\n",
    "     )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итого наилучшее качество 0.6514 дала реккурентная нейронная сеть c использованием 4х\n",
    "#входных векторов, а так же добавлением к полносвязному слою вектор исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
